---
# This script will demonstrate how to analyze the amphibian data collected as 
# part of the LongTerm Ecological Monitoring Initiative

#
# Only one study area at time can only be analyzed with a script. 
#
# This was programmed by Carl James Schwarz, Statistics and Actuarial Science, SFU
# cschwarz@stat.sfu.ca
#
# 2020-11-25 Created quatro document
# 2017-03-27 Separated egg mass by SPECIES_CODE. Imputed 0 counts when SPECIES_CODE not seen in a year
# 2017-02-28 First Edition

# Summary of calling protocol
#    Define a survey transect along or through your wetland. … 
#    Surveyors visit the monitoring site(s) in spring and listen for calling males, 
#    recording the SPECIES_CODE and approximate number of each. 
#    Repeat surveys increase the probability that SPECIES_CODE will be detected.”

# Summary of visual protocol
#    Surveyors monitor breeding site(s) during the active season (spring to fall),
#    walking the shoreline of a wetland recording all SPECIES_CODE and life stages 
#    encountered. These include egg masses, tadpoles and adults. 
#    Repeat surveys increase the probability that SPECIES_CODE will be detected.”

# A separate analysis is done on EACH SPECIES_CODE present

title: "`r paste0('Amphibians - LTEM - ',params$STUDY_AREA_NAME)`" 
date: today
date-format: YYYY-MM-DD
format: 
  html:
    toc: true
    number-sections: true
    self-contained: true
  pdf:
    toc: true
    number-sections: true
  docx:
    toc: true
    number-sections: true

params:
  STUDY_AREA_NAME: "Champion"
#  STUDY_AREA_NAME: "Alice Lake"
# STUDY_AREA_NAME: "Hai Lake"
---

```{r}
#| echo: false
#| warning: false
#| message: false

# load libraries
library(car)       # for testing for autocorrelation (2 libraries needed - see dwtest)
library(flextable) # for tables that look nice
library(ggfortify) # for residual and other diagnostic plot
library(ggplot2)   # for plotting
library(insight)   # for formatting p-values
library(lmtest)    # for testing for autocorrelation
library(lubridate) # date conversions
library(plyr)      # for group processing
library(readxl)    # for opening the Excel spreadsheets and reading off them
library(reshape2)  # for melting and casting
library(lmerTest)  # for the linear mixed modelling
library(stringr)   # string handling (like case conversion)

# Load some common functions
source("../2022-CommonFiles/common.functions.R")
source("../2022-CommonFiles/read.LTEM.R")
```

# Issues with this protocol that need to be resolved before doing any analyses

* Multiple types of transects. Both auditory and visual transects can be performed, and sometimes in the same year. Different species can be detected
under each type of survey (e.g., salamanders cannot be detected under auditory surveys).
* Timing of survey. In some site.years, multiple surveys are conducted. How should these be combined? For example, amphibians may be more vocal during
the breeding season and not outside the breeding season. The breeding season may be site.year.species dependent. 
* Accounting for detection probabilities. Just because an amphibian species was not detected, does not imply that was not present. The surveyor
may have been unlucky and not seen/heard the species when the transect was run. 

I recommend that a revised protocol based on the North American Amphibian Monitoring Plan be used that accounts for the above factors.
The survey protocol has been extensively field tested and should give you much better data. As well, Parks Canada has an amphibian monitoring plan
for sites in the Banff/Lake Louise/Yoho Parks area that could also be adopted quickly.

I don't thing that this protocol will yield anything useful in its present form.



# Summary of Amphibian LTEM protocol

## Basic protocol

There are two protocols – calls and visual surveys.

As taken from the protocol document for call surveys:

> “Define a survey transect along or through your wetland. … 
> Surveyors visit the monitoring site(s) in spring and listen for calling males, 
> recording the SPECIES_CODE and approximate number of each. 
> Repeat surveys increase the probability that SPECIES_CODE will be detected.”

As taken form the protocol document for visual surveys:

> “Surveyors monitor breeding site(s) during the active season (spring to fall), 
> walking the shoreline of a wetland recording all SPECIES_CODE and life stages encountered. 
> These include egg masses, tadpoles and adults. 
> Repeat surveys increase the probability that SPECIES_CODE will be detected.”

The data collected under this protocol at each survey consists of:

-	SPECIES_CODE. The SPECIES_CODE of amphibian counted.
-	Life Stage. The life stage of the SPECIES_CODE. 
-	Count. The number of amphibians at this lifestage.



## Cautions about the protocol.

### Don’t use 0 to indicate a missing value.

If no SPECIES_CODE were seen during a visit, this is indicated by the
lack of a record for that visit. 
It will be necessary to assume that all SPECIES_CODE will have been searched 
for at each visit and that lack of count for a SPECIES_CODE implies 
it was searched for and not seen, rather than the observed 
did not know how to identify the SPECIES_CODE.

It is unclear how NO amphibians of SPECIES_CODE will be recorded in the database?

If no visit was made to a transect, then there are no records 
in the General Survey for that transect. 
One must infer that if there are no records for transect at a date that it was not visited. 
The Transect Information worksheet only has information on the transect label 
and not when they were visited. 
It is preferable to include in this sheet the visit dates of each transect 
in that year explicitly rather than trying to infer this information 
from the General Survey sheet.

**This may have been corrected in the new datasets**


## Database structure

The database for this protocol is a series of Excel workbooks 
with multiple sheets in each workbook. 
The Transect Information sheet contains the information on the transect 
available for this year. If a transect is not visited, this is 
indicated by a no records in the General Survey workseeht. 
The General Survey sheet contains the information collected. 
There are multiple lines per visit. 
If a visit was done but no amphibians were detected, then the SPECIES_CODE code is set to missing with a count of 0.

The relevant fields on the General Survey worksheet are:

-	*Transect* Label.
-	*Date*. The date the data was collected. The Year is extracted from this date.
-	SPECIES_CODE. What SPECIES_CODE were seen
- *EggMasses* - number of eggmasses detected
- *Adults*    - number of adults counted


# Reading and checking the data

The database was read for all record pertaining to the
`r params$STUDY_AREA_NAME`. The following files were found:

```{r}
#| echo: false

data.extract <- read.LTEM.data(study.type="Amphibians",
                                         site.names=params$STUDY_AREA_NAME)

if(length(data.extract$user.dat)==0){
    # no data extracted
    cat("\n\n\n*** ERROR *** No data extracted. Check your STUDY_AREA_NAME in the yaml \n")
    knitr::knit_exit()
    stop()
}

amph.df <- data.extract$user.data

```

The following surveys were found:

```{r}
#| echo: false
cat("Surveys with the data \n")
data.extract$projects[,c("SPI_PROJECT_ID","SURVEY_ID","START_DATE","STUDY_AREA_NAME")]
```

The following data editing was performed

## Variables names corrected for *R*

Variable names in *R* must start with a letter and contain letters or numbers or underscores.
Blanks in variable names are not normally allowed, nor are special characters such as %.
These are normally replaced by periods (".") in the variable name.

```{r}
#| echo: false

#------------ Data Editing -----------
# fix up variable names in the data.frame.
# Variable names in R must start with a letter and contain letters or number or _. 
# Blanks in variable names are not normally allowed. Blanks will be replaced by . (period)
cat("\nOriginal variable names in data frame\n")
names(amph.df)

names(amph.df) <- make.names(names(amph.df))

cat("\nCorrected variable names of data frame\n")
names(amph.df)
```

## How many years of data are available?

```{r}
#| echo: false
#| error: true
#| 

cat("\n\nThe number of TRANSECTS run by year are \n")
xtabs(~STUDY_AREA_NAME+Year, data=amph.df, exclude=NULL, na.action=na.pass)  # check the date formats. 

if(length(unique(amph.df$Year))<3){
    # insufficient data extracted
    cat("\n\n\n*** ERROR *** Less than 3 years of data. No analysis possible \n")
    knitr::knit_exit()
    stop()
}
```



## Checking Study Area Name

The Study Area Name should be recorded consistently across years, otherwise 
it may indicate that different sites are being studies. The study area name
is converted to Title Case.

The list of Study Area Names by year in the data is:

```{r}
#| echo=FALSE

# Check that the Study Area Name is the same across all years
# Look at the output from the xtabs() to see if there are multiple spellings 
# of the same STUDY_AREA_NAME.

# We will convert the STUDY_AREA_NAME to Proper Case.
amph.df$STUDY_AREA_NAME <- stringr::str_to_title(amph.df$STUDY_AREA_NAME)
xtabs(~STUDY_AREA_NAME+Year, data=amph.df, exclude=NULL, na.action=na.pass)

if(!all(grepl(params$STUDY_AREA_NAME, amph.df$STUDY_AREA_NAME, ignore.case=TRUE))){
  cat("*** ERROR *** STUDY_AREA_NAMEs are not consistent\n")
  cat("A tabulation of STUDY_AREA_NAMEs in datasets is \n")
  xtabs(~STUDY_AREA_NAME, data=amph.df, exclude=NULL, na.action=na.pass)
  cat("Requested study area was ", params$STUDY_AREA_NAME,  "\n")
  stop("Input data is not all from ", params$STUDY_AREA_NAME)
}

if(length(unique(amph.df$STUDY_AREA_NAME))>1){
   cat("*** ERROR *** More than one study area found \n")
   cat("\n\nThe number of records by year are \n")
   xtabs(~STUDY_AREA_NAME+Year, data=amph.df, exclude=NULL, na.action=na.pass)  # check the date formats. 
   stop()
}

```

You should also check the transect labels for typos, e.g., inconsistencies
across years. This is difficult to automate and needs a human touch.

```{r}
#| echo=FALSE

# Check the TRANSECTs for typos
xtabs(~STUDY_AREA_NAME+TRANSECT, data=amph.df, exclude=NULL, na.action=na.pass)
xtabs(~TRANSECT+Year,            data=amph.df, exclude=NULL, na.action=na.pass)
```


## Checking SPECIES_CODE code

The SPECIES_CODE code should be the same across the files.

```{r}
#| echo: false
# Check the SPECIES_CODE code to make sure that all the same
# This isn't used anywhere in the analysis but is useful to know
xtabs(~SPECIES_CODE+Year, data=amph.df, exclude=NULL, na.action=na.pass)

if(length(unique(amph.df$SPECIES_CODE))>1){
   cat("*** WARNING *** More than one SPECIES_CODE name found \n")
   cat("\n\nThe number of records by SPECIES_CODE and year are \n")
   xtabs(~SPECIES_CODE+Year, data=amph.df, exclude=NULL, na.action=na.pass)  # check the date formats. 
   #stop()
}

```


```{r}
#| echo: false

# Get the file prefix
file.prefix <- make.names(amph.df$STUDY_AREA_NAME[1])
file.prefix <- gsub(".", '-', file.prefix, fixed=TRUE) # convert blanks to -
file.prefix <- file.path("Plots", file.prefix)
```


# Single Site Analysis

Date for the `r params$STUDY_AREA_NAME` are available from 
`r min(amph.df$Year, na.rm=TRUE)` to 
`r max(amph.df$Year, na.rm=TRUE)`. 


This design could have multiple transects that are repeatedly measured 
over time with multiple plots measured on each transect that are also 
repeatedly measured over time. 
Please refer to the Fitting Trends with Complex Study Designs document in the 
CommonFile directory for information on fitting trends with complex study designs. 
For the Alice Lake Example, there is only one transect which 
simplifies the analysis considerably. 

All analyses were done using the R (R Core Team, 2022)  analysis system. 
The *R* code is general enough that if more than one transect is present, 
it will automatically choose the more complex linear mixed models as seen in the other protocols.
All plots are also saved as separate *png files for inclusion into other reports.


## Number of Egg Masses

This analysis will look at trend in the total number of 
detected egg masses (for each SPECIES_CODE, and over all SPECIES_CODE). 
The current data is extremely sparse at the SPECIES_CODE level and likely to be uninformative.

A key problem with this protocol is the emphasis in the previous paragraph on detection
probabilities. 
It is not possible to count all of the egg masses laid in the study area; 
it is also unlikely that all egg masses along the (fixed) transects will be 
detected in each year. 
Consequently, it is necessary to make the **VERY STRONG** 
assumption that detectability is constant over time for each transect. 
This may be violated, for example, when different numbers of visits 
are made across years on the same transect (e.g. two visits were made in 2013, 
while only one visit was made in 2014 and 2015). 
Presumably, if more visits are made to a transect, then more egg masses may be detected.

We also need to make the strong assumption that egg masses are 
not double counted across multiple visits to the same transect. 
There is no information stored on the database on the exact 
location where an egg mass was located so it is difficult to verify this information.

Even if the above assumptions are satisfied, the number of observed 
egg masses is only an **INDEX** to the population number of egg masses.

The data is first summarized to the year level 
for each transect counting the number of records that identify an egg mass. 
This reduces the data to one measurement per transect per site/year. 

We first need to impute 0 values for a SPECIES_CODE if not listed
as being detected in a year.

```{r}
#| echo: true

# Must impute 0 values for SPECIES_CODE not present in a year


xtabs(~Year+EggMasses,  data=amph.df, exclude=NULL, na.action=na.pass)
xtabs(EggMasses ~ SPECIES_CODE+Year, data=amph.df, exclude=NULL, na.action=na.pass)
```

**DATA is NOT consistent across years**


```{r}
#| echo: false

# Count the total number of egg masses seen by SPECIES_CODE
eggmass.count.by.SPECIES_CODE <- plyr::ddply(amph.df,
                                  c("STUDY_AREA_NAME","TRANSECT","Year","SPECIES_CODE"),
                                  plyr::summarize,
                       EggMasses=sum(EggMasses,na.rm=TRUE))
cat("The number of egg masses counted by SPECIES_CODE \n")
eggmass.count.by.SPECIES_CODE

# Count the total number of egg masses seen for ALL SPECIES_CODE
eggmass.count.all.SPECIES_CODE <- plyr::ddply(amph.df, 
                                         c("STUDY_AREA_NAME","TRANSECT","Year"), 
                                         plyr::summarize,
                       EggMasses=sum(EggMasses, na.rm=TRUE))
eggmass.count.all.SPECIES_CODE$SPECIES_CODE <- 'ALL.SPECIES_CODE'

eggmass.count <- rbind(eggmass.count.by.SPECIES_CODE, eggmass.count.all.SPECIES_CODE)



# Need to impute 0 values for SPECIES_CODE not seen in a year

# check out records where eggmass count not identified
select <- eggmass.count$SPECIES_CODE %in% c("AMPHIBION","Unidentifed") # Notice type in unidentified
eggmass.count[ select,]

eggmass.count <- eggmass.count[ !select, ] 


# Create a record for each SPECIES_CODE x each year
complete.SPECIES_CODE.year <- expand.grid(STUDY_AREA_NAME=unique(eggmass.count$STUDY_AREA_NAME),
                                     TRANSECT =unique(eggmass.count$TRANSECT),
                                     SPECIES_CODE=unique(eggmass.count$SPECIES_CODE),
                                     Year   =unique(eggmass.count$Year,  stringsAsFactors=FALSE))
eggmass.count <- merge(complete.SPECIES_CODE.year, eggmass.count, all.x=TRUE)

# replace all NA by 0
eggmass.count$EggMasses[ is.na(eggmass.count$EggMasses)] <- 0

# check that every SPECIES_CODE is given in each year
cat("A summary of the egg-masses seen by SPECIES_CODE and year is \n")
xtabs(EggMasses~SPECIES_CODE+Year, data=eggmass.count, exclude=NULL, na.action=na.pass)
```

A summary plot of the (reduced) data is shown in @fig-em-prelim.

```{r}
#| echo: false
#| fig-cap: "Summary plot of the number of egg masses seen during VI count."
#| label: fig-em-prelim
#| warning: false
#| message: false

# Make a preliminary plot of total count by date
prelim.egg.plot <- ggplot(data=eggmass.count, aes(x=Year, y=EggMasses, 
                                                  color=TRANSECT, linetype=TRANSECT))+
   ggtitle("Amphibian egg mass count data")+
   ylab("Amphibian egg masses")+
   geom_point(position=position_dodge(width=.5))+
   geom_line( position=position_dodge(width=.5))+
   facet_wrap(~interaction(STUDY_AREA_NAME,SPECIES_CODE), ncol=2, scales="free_y")+
   scale_x_continuous(breaks=min(eggmass.count$Year,na.rm=TRUE):max(eggmass.count$Year,na.rm=TRUE))#+
   #scale_y_continuous(breaks=1:100)
prelim.egg.plot 
ggplot2::ggsave(plot=prelim.egg.plot, 
       file=paste(file.prefix,'-plot-prelim-egg.png',sep=""),
       h=6, w=6, units="in",dpi=300)
```



If a single transect is done in each year, a (quasi)-Poisson generalized linear model
is fit. The quasi-Poisson model accounts for potential overdispersion.
The model is:
$$NEggMasses = Year$$
where

- $NEggMasses$ is the number of egg masses for that transect in a year; and 
- $Year$ represents the calendar year trend over time.  

This model assume that effects are multiplicative over time, 
so that the actual fit is done on the logarithmic scale. 
For example, a trend may assume that there is constant 5% change 
over time rather than a fixed 1 unit change per year. 
An approximate analysis could be done using regular linear regression 
if you analyze the log(NEggMass+.5), where the offset of 0.5 is use to avoid taking 
$log(0)$. 


If there are multiple transects, a mixed linear model is fit (in the standard notation)
on the logarithmic scale. This will automatically account for overdispersion.
$$log(NEggMasses+.5) = Year + TRANSECT(R) + YearF(R))$$

where 

- $TRANSECT(R)$ is the (random) transect-specific effects;
- $YearF(R)$ is the year-to-year proccess error.

These models are fit using the *glm()* or *lmer()* functions in *R* respectively
and results summarized in @fig-em-summary.


```{r}
#| echo: false



#eggmass.count2 <- eggmass.count
#eggmass.count2$TRANSECT ='xx'
#eggmass.count2$EggMasses <- rpois(1, eggmass.count$EggMasses)
#eggmass.count2
#eggmass.count <- rbind(eggmass.count, eggmass.count2)


# This is a regression analysis with Year as the trend variable 
# In this case, there is only one transect, 
# so it is not necessary to have the TRANSECT in the model
# We also don't need to model process (year specific effects) because there is only 1 transect

# Fit a linear regression for each SPECIES_CODE 
fits<- dlply(eggmass.count, "SPECIES_CODE", function(eggmass.count){
   cat("\n\n\n *** Starting analysis for SPECIES_CODE ", as.character(eggmass.count$SPECIES_CODE[1]), "\n")
   if(length(unique(eggmass.count$TRANSECT))>1){
      eggmass.count$TRANSECTF <- factor(eggmass.count$TRANSECT)
      eggmass.count$YearF     <- factor(eggmass.count$Year)
      egg.fit <- lmerTest::lmer(log(EggMasses+.5) ~ Year + (1|TRANSECTF) + (1|YearF) ,
                                data=eggmass.count)
      print(anova(egg.fit, ddf='Kenward-Roger'))
      print(summary(egg.fit))
      print(VarCorr(egg.fit))
   }
   if(length(unique(eggmass.count$TRANSECT))==1){
       # with only 1 transect, not necessary to put random effects effect in the model
       egg.fit <- glm(EggMasses ~  Year , data=eggmass.count, family=quasipoisson)
       print(Anova(egg.fit, test="F", type=3))
       print(summary(egg.fit))
   }
   list(SPECIES_CODE=eggmass.count$SPECIES_CODE[1], fit=egg.fit, 
        n.transects=length(unique(eggmass.count$TRANSECT)),
        STUDY_AREA_NAME = eggmass.count$STUDY_AREA_NAME[1],
        eggmass.count = eggmass.count)
})
```


```{r}
#| echo: false

# extract a table of statistics for each study area x SPECIES_CODE combiations
egg.slopes <- plyr::ldply(fits, function(x){
  #browser()
  if(x$n.transects==1){
     eggmass.count <- x$eggmass.count    
     egg.fit       <- x$fit
     egg.slopes <- data.frame(
        STUDY_AREA_NAME =unlist(x$STUDY_AREA_NAME),
        slope    = coef(egg.fit)["Year"],
        slope.se = sqrt(diag(vcov(egg.fit)))["Year"],
        p.value  = summary(egg.fit)$coefficients[row.names(summary(egg.fit)$coefficients)=="Year"  ,"Pr(>|t|)"],
        stringsAsFactors=FALSE
     )
  }
  if(x$n.transects>1){
     eggmass.count <- x$eggmass.count
     egg.fit <- x$fit
     egg.slopes <- data.frame(
          STUDY_AREA_NAME = unlist(x$STUDY_AREA_NAME),
          slope           = fixef(egg.fit)["Year"],
          slope.se        = summary(egg.fit)$coefficients["Year","Pr(>|t|)"],
          p.value         = summary(egg.fit)$coefficients[row.names(summary(egg.fit)$coefficients)=="Year"  ,"Pr(>|t|)"], 
          stringsAsFactors=FALSE)
   }
   egg.slopes
})
#egg.slopes


# compute the fitted values from the model
egg.fitted <- ldply(fits, function(x){
   #browser()
   eggmass.count <- x$eggmass.count
   egg.fit       <- x$fit
   TRANSECT <- unique(as.character(eggmass.count$TRANSECT))
   newdata <- expand.grid(Year=seq(min(eggmass.count$Year, na.rm=TRUE),max(eggmass.count$Year, na.rm=TRUE), .1),
                          TRANSECTF=TRANSECT)
   newdata$TRANSECT <-as.character(newdata$TRANSECTF)
   if(x$n.transects==1){
      newdata$pred.mean <- predict(egg.fit, newdata=newdata,type="response")
   }
   if(x$n.transects>1){
      newdata$pred.mean <- exp(predict(egg.fit, newdata=newdata, type="response", re.form=~0))
   }
   # we now must average over all of the transect labels
   egg.fitted <- plyr::ddply(newdata, c("Year","TRANSECT"), plyr::summarize, pred.mean=mean(pred.mean))
   #browser()
   egg.fitted$STUDY_AREA_NAME <- unlist(x$STUDY_AREA_NAME[1])
   egg.fitted
})
#egg.fitted
```

```{r}
#| echo: false
#| fig-cap: "Summary plot of the trend in number of egg masses. Because the analysis was done on the logarithmic scale, the fitted trend line is not a straight line but curved."
#| label: fig-em-summary
#| warning: false
#| message: false

# Plot with trend line 
egg.plot.summary <- ggplot2::ggplot(data=eggmass.count,
                                    aes(x=Year, y=EggMasses))+
   ggtitle("Amphibian eggmass count ")+
   ylab("Amphibian Eggmass Count")+
   geom_point(size=3, aes(color=TRANSECT))+
   facet_wrap(~interaction(STUDY_AREA_NAME,SPECIES_CODE), ncol=2, scales="free_y")+
   geom_line(data=egg.fitted, aes(x=Year,y=pred.mean))+
   scale_x_continuous(breaks=min(eggmass.count$Year,na.rm=TRUE):max(eggmass.count$Year,na.rm=TRUE))+
   geom_text(data=egg.slopes, aes(x=min(eggmass.count$Year, na.rm=TRUE), y=max(eggmass.count$EggMasses, na.rm=TRUE)), 
             label=paste("Slope (on log scale) : ",round(egg.slopes$slope,2), 
                         " ( SE "  ,round(egg.slopes$slope.se,2),")",
                         " \np :"    ,round(egg.slopes$p.value,3)),
                         hjust="left",vjust="top")+
   theme(legend.position="top")
egg.plot.summary
ggsave(plot=egg.plot.summary, 
       file=paste(file.prefix,'-egg-plot-summary.png',sep=""),
       h=6, w=6, units="in", dpi=300)

```

The estimated slopes for each SPECIES_CODE and for all SPECIES_CODE pooled are:

```{r}
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Estimated slopes (on logarithmic scale)"
temp<- egg.slopes
temp$p.value <- insight::format_p(egg.slopes$p.value)

ft <- flextable(temp)
ft <- colformat_double(ft, j="slope", digits=2)
ft <- colformat_double(ft, j="slope.se", digits=2)
ft <- set_header_labels(ft, "slope"="Slope", "p.value"="P-value", "slope.se"="SE")
ft <- set_table_properties(ft, layout = "autofit")
ft <- set_caption(ft, caption="Estimated slopes on the logarithmic scale")
ft


```

Because the analysis is done on the logarithmic scale, the
interpretation of the slopes is straight forward. For example, if the estimated
slope is .02, then the number of eggmasses is estimated to be increasing by 2%/year.


```{r}
#| echo: false
#| fig-cap: "Model fit diagnostic plots from trend in egg masses"
#| label: fig-em-resid
#| warning: false
#| message: false


# Get the model diagnostic plots
l_ply(fits, function(x){
    cat("\n\n\n *** Diagnostic plot for SPECIES_CODE ", as.character(x$SPECIES_CODE), "\n")
   if(x$n.transects>1){
      diag.plot <- sf.autoplot.lmer(x$fit)  # residual and other diagnostic plots
      #browser()
      plot(diag.plot)
   }
   if(x$n.transects==1){
      diag.plot <- autoplot(x$fit)  # residual and other diagnostic plots
      #browser()
      gridExtra::grid.arrange(grobs = diag.plot@plots, top = paste("SPECIES_CODE ", x$SPECIES_CODE))
      #show(diag.plot)
   }
   ggplot2:: ggsave(#plot=diag.plot, 
          file=paste(file.prefix,"-egg-residual-plot-",x$SPECIES_CODE,".png",sep=""),
          h=6, w=6, units="in", dpi=300)
})
```

Residual plots are presented above.
With only `r length(unique(amph.df$Year))` years of data, 
the plots are not very informative. In the upper left corner is a plot of residuals vs. 
the fitted values. A good plot will show a random scatter around 0. 
Any large deviations from 0 should be investigated as potential outliers. 
In the upper right is a normal probability plot. Points should be close to the dashed reference line. 
Fortunately, the analysis is fairly robust against non-normality 
so only extreme departures are worrisome. 
The bottom left plot examine the assumption that the variation 
about the line is constant over the line. 
You would expect to see a constant band of points. 
Finally the bottom right plot is a leverage plot – this is not useful for this simple model and can be ignored. 

It will also be possible to covariates such as mean winter temperature 
or degree days in the year to try and explain some of the variation over time 
using a multiple regression. With only `r length(unique(amph.df$Year))`
years of data available, this not sensible.


```{r}
#| echo: false
#| warning: false
#| message: false

em.ac <- ldply(fits, function(x){
   #cat("\n\n\n *** Checking for autocorrelation for SPECIES_CODE ", as.character(x$SPECIES_CODE), "\n")
   eggmass.count <- x$eggmass.count
   # check for autocorrelation
   if(x$n.transects>1){
      eggmass.count$resid <- log(eggmass.count$EggMasses+.1) - 
        predict(x$fit, newdata=eggmass.count, re.form=~0)
   }
   #browser()
   if(x$n.transects==1){
      eggmass.count$resid <- log(eggmass.count$EggMasses+.1) - 
        predict(x$fit, newdata=eggmass.count, type="link")
   }
   mean.resid <- plyr::ddply(eggmass.count, "Year", summarize, mean.resid=mean(resid))
   resid.fit <- lm( mean.resid ~ 1, data=mean.resid)
   dwres1 <- car::durbinWatsonTest(resid.fit)
   #print(dwres1)
   dwres2 <- lmtest::dwtest(resid.fit)
   #print(dwres2)
   #browser()
   data.frame(ac=dwres1$r,
              ac.p.value=insight::format_p(dwres1$p))
})
```

Whenever an analysis of a trend over time is conducted, the analysis 
should test and adjust for autocorrelation. 
Autocorrelation usually isn’t a problem (and likely cannot be detected) 
unless you have 10+ years of data. 
The test for autocorrelation commonly used is the Durbin-Watson test and the following table
is a summary of the results.

```{r}
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Estimated autocorrelation"
#| 
ft <- flextable(em.ac)
ft <- colformat_double(ft, j="ac", digits=2)
ft <- set_header_labels(ft, "ac"="Autocorrelation", "ac.p.value"="P-value")
ft <- set_table_properties(ft, layout = "autofit")
ft <- set_caption(ft, caption="Estimated autocorrelation")
ft
```

If there is evidence of autocorrelation (p-value is small) with a postive autocorrelation
please
contact me for assistance.
Negative autocorrelation is not a concern, but indicate a "cyclical" trend
in population numbers (i.e., high numbers in one year followed by low
numbers in the next year, and vice versa) which may be of biological interest.

This analysis was conducted at the total count level (over all SPECIES_CODE) 
and also for individual SPECIES_CODE – but the data are likely to very sparse 
and not useful for individual SPECIES_CODE. 
One potential problem is that in some cases, SPECIES_CODE information is only 
recorded at the Genus or higher level.  In these case, this data will have to 
discarded when the analysis is done at the SPECIES_CODE level, but then you are 
making an implicit assumption that recording at the Genus level happens at random 
and is unrelated to the response. 
If this assumption is violated (e.g. perhaps when there are larger 
number of amphibians, it is too difficult to record at the individual SPECIES_CODE level) 
then this is not occurring at random and some effort must be made 
to “split” the genus level information among the SPECIES_CODE.

In theory, the actual number of eggs in each egg mass could also be 
used rather simply the number of egg masses. I did not do this analysis 
because (a) it makes little sense to average the size of the egg mass 
over the different SPECIES_CODE and (b) the number of eggs in the egg 
mass may not represent the total number laid because of unknown amounts of predation.




```{r}
#| echo: false
#----------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------
```

## Number of Adults. 
A similar analysis can be done on the total number of adult amphibians detected. 
In Alice Lake there were only a total of 7 frogs detected over the three years 
– the data is just too sparse to analyze at this time.

# Power analysis

A power/sample size analysis was conducted to determine the number of years of sampling needed to detect
changes over time. The steps in the power/sample size analysis are:

- Compute a single number summarizing the response at this site in each year. The number of eggmasses is currently recorded at the transect level 
within each year so this needs to be averaged. Only the number of egg massess for all species will be used in the poper analysis.
- Analyze the log(mean response) using a simple linear regression. This will give an estimate of the combined year-specific and sampling variation
around regression line (overall sd).
- Use the overall SD to estimate power and sample size requirements.

Here are the overall number of eggmasss for each year for each response:

```{r}
#| echo: false
#| warning: false
#| message: false
#| error: true

# get the mean values of 1 number per site per year

count.mean1 <- plyr::ddply(eggmass.count.all.SPECIES_CODE, "Year", function(x){
     data.frame(mean.count=mean(x$EggMasses))
})
count.mean1$mean.response <- count.mean1$mean.count
count.mean1$Response <- "Eggmasses - all species"

all.resp <- plyr::rbind.fill(count.mean1)
all.resp

```

The above data needs to be checked if there are any suspicious values.  

We use the *lm()* function to fit linear regression over time on the log(scale) and obtain the combined year-specific effect (process error) 
plus sampling variation standard deviation (@tbl-resid-sd).

```{r}
#| echo: false
#| warning: false
#| message: false
#| error: true
#| tbl-cap: "Estimated residual (process + sampling) standard deviation"
#| label: tbl-resid-sd

# if any of the values are zero, add a small offset
all.resp <- plyr::ddply(all.resp, "Response", function(x){
     offset <- .5 #smallest non-zero postive value is 1)
     x$mean.response <- x$mean.response + offset
     x
})

# fit a regression line on the log(scale) and get the residual sd
residual.sd <- plyr::ddply(all.resp, "Response", function(x){
    fit <- lm(log(mean.response) ~ Year, data=x)
    sd  <- summary(fit)$sigma
    data.frame(sd=sd)
})

ft <- flextable(residual.sd)
ft <- width(ft, j=1, width=2)
ft <- width(ft, j=2, width=2)
ft <- colformat_double(ft, j=2, digits=4)
ft <- set_header_labels(ft, values = list(sd="Process + sampling SD"))
 
ft
```

This is then used to estimate the power to detect various proportional changes over time (@fig-power).

```{r}
#| echo: false
#| warning: false
#| message: false
#| error: true
#| fig-cap: "Estimated power to detect proportional changes over time"
#| label: fig-power

# remove any missing values for resid.sd
residual.sd <- residual.sd[!is.na(residual.sd$sd),]

# estimate power at changes of 0 to .10/year with sample sizes of 5 to 20 years for each response
scenarios <- expand.grid(n.years=seq(5,20,1),
                         slope  =seq(0, .1, .02))
power.detect <- plyr::ddply(residual.sd, "Response", function(x, scenarios){
   
   power <- plyr::adply(scenarios,1, function(scenario,x){
      #browser()
      power <- slr.power.stroup(Trend=scenario$slope,
                                Xvalues=1:scenario$n.years,
                                Process.SD=x$sd,
                                Sampling.SD=0)
      power
   },x=x)
}, scenarios=scenarios)

ggplot(data=power.detect, aes(x=n.years, y=power.2s, color=as.factor(slope)))+
   ggtitle("Estimated power", subtitle="alpha=0.05")+
   geom_point()+
   geom_line()+
   facet_wrap(~Response, ncol=1)+
   ylab("Power")+xlab("Number of years in the study")+
   scale_color_discrete(name="Proportional\nyearly\nslope")+
   xlim(0,NA)+ylim(0,1)+
   geom_hline(yintercept=0.8)


```
 
The proportional yearly slope indicates the effect size of interest. For example, a value
of .02 would indicated a 2% change/year in the mean response.
 
In cases of high variability, the power is uniformly low 
to detect the yearly proportion change over time. 
In cases of low variability power is uniformly very high
to detect the yearly proportion change over time.


# Summary
Some caution is required to ensure that all transects are visited 
equally often in a year. 
In this balanced design, it is straightforward to compute statistics 
over all measurements of a transect and all transects in a year have the same number of visit. 
It is possible to modify the analysis is only some transects are visited 
on a particular date with an unequal number of visits to a transect in a year. 
A simple way to deal with unbalance would be to delete some of the observations, 
but better methods are available.

Trends over time could also occur in the diversity of the amphibians. 
In theory, standard diversity measures could be used and tracked over time, 
but these have a very strong 
assumption that all SPECIES_CODE are equally detectable by the observer. 
This is unlikely to be true. Secondly, the actual counts are quite small, 
and diversity measures that rely on actual counts (e.g. Simpson’s diversity) 
will not perform well. 
For this reason, I do not recommend an analysis on the diversity of the observations.
I am extremely dubious that this protocol as implemented 
will produce any useful monitoring information at the study area level 
except for disaster detection (e.g. all SPECIES_CODE vanish). 
Even then, the absence of a detection does not imply that the SPECIES_CODE was not present – 
it could simply be a false negative. 
The current study does not provide any information to estimate detection probabilities.

As an example of how this protocol could be improved is based on 
large scale surveys of occupancy. 
The shoreline would be divided in many (at least 50) segments. 
On each visit, the presence/absence of amphibians would be recorded at the segment level. 
Then standard occupancy models could be used to estimate the proportion of 
segments that are occupied. 
Changes in the occupancy probability over time would be an 
indication that the population is increasing/decreasing over time.

Or this particular study area could be embedded into a much larger 
regional analysis where again, multiple visits are made 
in a year to estimate detection probabilities and changes in occupancy serve as an index to changes in the population.



# References

Kuznetsova A, Brockhoff PB, Christensen RHB (2017). 
lmerTest Package: Tests in Linear Mixed Effects Models.
Journal of Statistical Software, 82, 1-26. 
doi:10.18637/jss.v082.i13

MacKenzie, D. I., J. D. Nichols, J. A. Royle, K. H. Pollock, L.L. Bailey, and J. E. Hines. 2005.
Occupancy Estimation and Modeling - Inferring Patterns and Dynamics of SPECIES_CODE Occurrence. 
Elsevier Publishing. 
 
R Core Team (2022). R: A language and environment for statistical computing. 
R Foundation for Statistical Computing, Vienna, Austria. 
https://www.R-project.org/.


