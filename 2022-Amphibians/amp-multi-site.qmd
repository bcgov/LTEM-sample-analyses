---
# This script will demonstrate how to analyze the amphibian data collected as 
# part of the LongTerm Ecological Monitoring Initiative

#
# This is an example of comparing trends across ECODOMAINS 
#
# This was programmed by Carl James Schwarz, Statistics and Actuarial Science, SFU
# cschwarz@stat.sfu.ca
#
# 2020-11-25 Created quatro document
# 2017-03-27 Separated egg mass by SPECIES_CODE. Imputed 0 counts when SPECIES_CODE not seen in a year
# 2017-02-28 First Edition

# Summary of calling protocol
#    Define a survey transect along or through your wetland. … 
#    Surveyors visit the monitoring site(s) in spring and listen for calling males, 
#    recording the SPECIES_CODE and approximate number of each. 
#    Repeat surveys increase the probability that SPECIES_CODE will be detected.”

# Summary of visual protocol
#    Surveyors monitor breeding site(s) during the active season (spring to fall),
#    walking the shoreline of a wetland recording all SPECIES_CODE and life stages 
#    encountered. These include egg masses, tadpoles and adults. 
#    Repeat surveys increase the probability that SPECIES_CODE will be detected.”

# A separate analysis is done on EACH SPECIES_CODE present

title: "Amphibians - LTEM - EcoDomain Comparison" 
date: today
date-format: "YYYY-MM-DD"
execute: 
  error: true
format: 
  html:
    toc: true
    number-sections: true
    self-contained: true
  pdf:
    toc: true
    number-sections: true
  docx:
    toc: true
    number-sections: true
---

```{r}
#| echo: false
#| warning: false
#| message: false
#| include: false

options(width=200)

# load libraries
library(bcmaps)    # to get the EcoDomains
library(broom.mixed)# for handling output from lmerTest
library(car)       # for testing for autocorrelation (2 libraries needed - see dwtest)
library(emmeans)   # for extracting the individual slopes
library(flextable) # for tables that look nice
library(ggfortify) # for residual and other diagnostic plot
library(ggplot2)   # for plotting
library(insight)   # for formatting p-values
library(lmtest)    # for testing for autocorrelation
library(lubridate) # date conversions
library(plyr)      # for group processing
library(readxl)    # for opening the Excel spreadsheets and reading off them
library(sf)
library(lmerTest)  # for the linear mixed modelling
library(stringr)   # string handling (like case conversion)

# Load some common functions
source("../2022-CommonFiles/common.functions.R")
source("../2022-CommonFiles/read.LTEM.R")
```


# Summary of Amphibian LTEM protocol

## Basic protocol

There are two protocols – calls and visual surveys.

As taken from the protocol document for call surveys:

> “Define a survey transect along or through your wetland. … 
> Surveyors visit the monitoring site(s) in spring and listen for calling males, 
> recording the SPECIES_CODE and approximate number of each. 
> Repeat surveys increase the probability that SPECIES_CODE will be detected.”

As taken form the protocol document for visual surveys:

> “Surveyors monitor breeding site(s) during the active season (spring to fall), 
> walking the shoreline of a wetland recording all SPECIES_CODE and life stages encountered. 
> These include egg masses, tadpoles and adults. 
> Repeat surveys increase the probability that SPECIES_CODE will be detected.”

The data collected under this protocol at each survey consists of:

-	*Transect* Label.
-	*Date*. The date the data was collected. The Year is extracted from this date.
-	SPECIES_CODE. What SPECIES_CODE were seen
- *EggMasses* - number of eggmasses detected
- *Adults*    - number of adults counted

## Database structure

The relevant fields extracted from the database are:

- *STUDY_AREA_NAME* and location (longitude and latitude)
-	*Transect Label*.
-	*Date*. The date the data was collected. The Year is extracted from this date.
-	*Count*. The number of calls heard on the transect on that date.
It is assumed that 0's have been already imputed on the database.

The longitude and latitude are used to find the EcoDomain of each study area.


# Reading and checking the data

## Extract all LTEM data

The database was queried for all observations from this protocol in the Province.

```{r}
#| echo: false
#| include: false

# get the data from the Excel work.books.
# we put the list of work books here, including the file type (xls or xlsx).
# You can put multiple stations here because the station information is included on the raw data

# Get the data base information and any corrections here
data.extract <- read.LTEM.data(study.type="Amphibians", site.names="**ALL**")
```


```{r}
#| echo: false
if(nrow(data.extract$user.data)==0){
    # no data extracted
    cat("\n\n\n*** ERROR *** No data extracted. See help \n")
    knitr::knit_exit()
    #stop()
}

amph.df <- data.extract$user.data
amph.df$STUDY_AREA_NAME_shrt <- substr(amph.df$STUDY_AREA_NAME,1,20)

```

The following surveys and years of surveys were found.

```{r}
#| echo: false
cat("Number of records in each study area x year combination \n")
xtabs(~STUDY_AREA_NAME_shrt+Year, data=amph.df, exclude=NULL, na.action=na.pass)
```

It is not necessary that every STUDY_AREA be measured in every year and the number of measurements at each STUDY_AREA
can vary within years and across years.

If STUDY_AREA is only measured in one year, it does not provide any information
on the trends and can be dropped. Similary, STUDY_AREAS with only 2 years of data, provide no information 
on the uncertainty; they can be retained or dropped.

STUDY_AREAs dropped for insuffient data are:

```{r}
#| echo: false
#| tbl-cap: 'Study areas dropped because of insufficient years of data'
n.years <- plyr::ddply(amph.df, c("STUDY_AREA_NAME"), plyr::summarize, n.years=length(unique(Year)))
n.years.drop <- n.years[ n.years$n.years <2,]

amph.df <- amph.df[ !amph.df$STUDY_AREA_NAME %in% n.years.drop$STUDY_AREA_NAME,]

ft <- flextable(n.years.drop)
ft <- width(ft, j=1, width=4, unit="in")
ft <- set_header_labels(ft, STUDY_AREA_NAME="Study Area", n.years="# years of data")
ft
```


## Ecodomain of each study area

The Ecodomain of each study area was obtained by looking up the mean latitude/longitude of observations for each STUDY_AREA
in the Ecoprovices provided in the *bcmaps* package. The classification of each STUDY_AREA
into its EcoDomain is:


```{r}
#| echo: false
#| message: false
#| warning: false

# there may be slight deviations in the lat/long within each study area, but presumably, the mean should be ine
site.long.lat <- plyr::ddply(amph.df, c("STUDY_AREA_NAME","STUDY_AREA_NAME_shrt"), plyr::summarize,
     LONGITUDE_DD= mean(LONGITUDE_DD),
     LATITUDE_DD = mean(LATITUDE_DD))

site.long.lat$ECODOMAIN <- get_ecodomain(site.long.lat[,c("LONGITUDE_DD","LATITUDE_DD")]) 

xtabs(~STUDY_AREA_NAME_shrt+ECODOMAIN, data=site.long.lat, exclude=NULL, na.action=na.pass)

if(any(is.na(site.long.lat$ECODOMAIN))){
   # no ecodomains should be missing
     cat("\n\n\n*** ERROR *** Some study areas do not have an ecodomain \n")
    knitr::knit_exit()
    #stop()
}

# check if at least 2 eco domains at at least 4 study areas and at least 3 years x 2 ecodomains x 4 study area
cat("# check if at least 2 eco domains at at least 4 study areas and at least 3 years x 2 ecodomains x 4 study area\n")

amph.df <- merge(amph.df, site.long.lat[,c("STUDY_AREA_NAME","ECODOMAIN")], by="STUDY_AREA_NAME")

```


## Checking species code

The species code should be the same across for all data values..
Note that in many years, a code of *NULL* was entered to indicate no squirrels of any species
were detected. **This table shows the total detections for each species.year combination over all the transects in all STUDY_AREAs and EcoDomains**

```{r}
#| echo: false
# Check the Species code to make sure that all the same
# This isn't used anywhere in the analysis but is useful to know
xtabs(~SPECIES_CODE+Year, data=amph.df, exclude=NULL, na.action=na.pass)

if(length(unique(amph.df$SPECIES_CODE))>1){
   cat("*** WARNING *** More than one species name found - OK if some are NULL \n")
   #stop()
}

```


```{r}
#| echo: false

# Get the file prefix
if(!dir.exists(file.path("Plots","zzMultiSite")))dir.create(file.path("Plots","zzMultiSite"))
file.prefix <- file.path("Plots", "zzMultiSite")
```

# Multi-Site Analysis

We will now compare the trends in the EcoDomains. 

This design has multiple transects that are repeatedly measured over time. 
Please refer to the Fitting Trends with Complex Study Designs document in the 
CommonFile directory for information on fitting trends with complex study designs. 

All analyses were done using the R (R Core Team, 2023)  analysis system. 
All plots are also saved as separate *png files for inclusion into other reports.


## Egg Masses

### Summarize to transect level

The data is first summarized to the transect-year level by finding 
the mean number of calls on a transect over multiple visits for each individual transect. 
This reduces the data to one measurement per transect per STUDY_AREA/year. 

The first few records are:

```{r}
#| echo: false
# Summarize the imputed data to one number per year per transect
# Count the total number of egg masses seen by SPECIES_CODE
eggmass.count.by.SPECIES_CODE <- plyr::ddply(amph.df,
                                  c("STUDY_AREA_NAME","STUDY_AREA_NAME_shrt","ECODOMAIN","TRANSECT","Year","SPECIES_CODE"),
                                  plyr::summarize,
                       EggMasses=sum(EggMasses,na.rm=TRUE))
cat("The number of egg masses counted by SPECIES_CODE \n")
#eggmass.count.by.SPECIES_CODE

# Count the total number of egg masses seen for ALL SPECIES_CODE
eggmass.count.all.SPECIES_CODE <- plyr::ddply(amph.df, 
                                         c("STUDY_AREA_NAME","STUDY_AREA_NAME_shrt","ECODOMAIN","TRANSECT","Year"), 
                                         plyr::summarize,
                       EggMasses=sum(EggMasses, na.rm=TRUE))
eggmass.count.all.SPECIES_CODE$SPECIES_CODE <- 'ALL.SPECIES_CODE'

eggmass.count <- rbind(eggmass.count.by.SPECIES_CODE, eggmass.count.all.SPECIES_CODE)


temp <- eggmass.count
temp$STUDY_AREA_NAME <- NULL
head(temp)

# make a transect label that is unique to each study area names
eggmass.count$SA.TRANSECT <- paste0(eggmass.count$STUDY_AREA_NAME, "....", eggmass.count$TRANSECT)

```


It is implicitly assumed that all transects are run on all days within a STUDY_AREA
so every transect has the same number of days of measurement. 
If transects are changed over time, that is not a problem, but transects 
should not be introduced or removed part way through a year.

### Preliminary plot

A summary plot of the mean number of calls in each year for each STUDY_AREA and
an the trends over time is shown in @fig-em-prelim.

```{r}
#| echo: false
#| fig-cap: "Summary plot of the data. The data is analyzed on the logarithmic scale."
#| label: fig-em-prelim
#| warning: false
#| message: false

# get one number per study area per year and plot these
eggmass.count.mean <- plyr::ddply(eggmass.count, c("SPECIES_CODE","STUDY_AREA_NAME","ECODOMAIN","Year"), plyr::summarize,
                                   EggMasses=mean(EggMasses))

prelim.plot <- ggplot(data=eggmass.count.mean[eggmass.count.mean$SPECIES_CODE=="ALL.SPECIES_CODE",], aes(x=Year, y=log(EggMasses+.5)))+
   ggtitle("Amphibian Egg Mass count data",
           subtitle="Each line represents one study area")+
   ylab("log(Mean EggMasses +.5)")+
   geom_point(position=position_dodge(width=.1))+
   geom_line( aes(group=STUDY_AREA_NAME), position=position_dodge(width=.1))+
   facet_grid(SPECIES_CODE~ECODOMAIN)+
   scale_x_continuous(breaks=integer_breaks())
prelim.plot 
ggsave(plot=prelim.plot, 
       file=file.path(file.prefix,'Plot-em-prelim.png'),
       h=4, w=6, units="in",dpi=300)

```
**Data is silly because database was not updated properly**

### Model

A non-parallel slope model is fit allowing for a different average slope (over the multiple STUDY_AREAs) 
in each EcoDomains (non-parallel slopes). Within each EcoDomain, each STUDY_AREA's slope is allowed to vary 
randomly around the average slope for the EcoDomain. Within each STUDY_AREA, each transect is allowed to have
a different intercept but common slope. Finally, we allow for year-specific factor within each EcoDomain.

The model, in a short-hand notation is:

$$log(EggMasses+.5) \sim \mathit{EcoDomain} + \mathit{Year} + \mathit{EcoDomain}:\mathit{Year}+
\mathit{StudyArea} + \mathit{TransectF(R)} + \mathit{StudyArea}:\mathit{Year(R)} + \mathit{YearF:EcoDomain(R)}$$

where 

- $log(EggMasses)$ is logarithm of the the number of Egg Masses for that transect in that year. An offset of 0.5
is used to avoid taking the logarithm of 0.
- $\mathit{Year}$ term represents the average (over all EcoDomains) calendar year trend over time. 
- $\mathit{EcoDomain}$ term represents a different intercept for each EcoDomain
- $\mathit{EcoDomain}:\mathit{Year}$ term represents the differential average slope for each EcoDomain
- $\mathit{StudyArea}:\mathit{Year(R)}$ term represents the random slopes within each EcoDomain for each study area
- $\mathit{TransectF(R)}$ represents the (random) transect effect; 
- $\mathit{YearF:EcoDomain(R)}$ represents the (random) year-specific effects (process error), thare are allowed
to vary across EcoDomains.

The 
The $\mathit{TransectF}$ term allows for the fact that transect-specific conditions 
may tend to affect the counts on this transect consistently over time. 
The $\mathit{YearF:EcoDomain}$ term represent the year-specific effects (process error) 
caused by environmental factors (e.g., a warmer than normal year may elict more calls from squirrels).

Model fit on the logarithmic scale assume that effects are multiplicative over time, 
so that the when the actual fit is done on the logarithmic scale, 
the trends are linear. For example, a trend may assume that there is constant 
5% change over time rather than a fixed 1-unit change per year. 
Some caution is needed if any of the values are 0 as log(0) is not defined. 
In these cases, a small constant (typically ½ of the smallest positive value in the dataset) 
is added to all values before the analysis proceeds.

The model was fit using the *lmerTest()* function (Kuznetsova, 2017) in *R* (R Core Team, 2023). 

We only look at the total Egg Masses over all species because the individual species data just too spares.

```{r}
#| echo: false
#| 

# create factors
eggmass.count$ECODOMAINF       <- factor(eggmass.count$ECODOMAIN)
eggmass.count$YearF            <- factor(eggmass.count$Year)
eggmass.count$TRANSECTF        <- factor(eggmass.count$SA.TRANSECT)
eggmass.count$STUDY_AREA_NAMEF <- factor(eggmass.count$STUDY_AREA_NAME)

eggmass.count.all <- eggmass.count[ eggmass.count$SPECIES_CODE=="ALL.SPECIES_CODE",]

count.fit.pvalue     <- NA # in case the model does not fit
count.fit.slope      <- NA
count.fit.slope.se   <- NA
count.fit.slope.anti <- NA

# See https://stats.stackexchange.com/questions/31569/questions-about-how-random-effects-are-specified-in-lmer
# This is a regression analysis with Year as the trend variable 
# In this case, there is only one transect, 
# so it is not necessary to have the TRANSECT in the model
# We also don't need to model process (year specific effects) because there is only 1 transect

# Fit a linear regression for each SPECIES_CODE 
# See https://stats.stackexchange.com/questions/31569/questions-about-how-random-effects-are-specified-in-lmer
count.fit <- lmerTest::lmer(log(EggMasses+.5) ~ Year + ECODOMAINF + Year:ECODOMAINF +
#                (1+Year|STUDY_AREA_NAMEF) +
                (1|STUDY_AREA_NAMEF) + (Year-1|STUDY_AREA_NAME) +
                (1|TRANSECTF) + 
                (1|YearF:ECODOMAINF), data=eggmass.count.all)

cat("\n\n")
anova(count.fit, ddf="Satterthwaite")
cat("\n\n")
summary(count.fit)

```


### Test for no difference in trends among EcoDomains

After the model is fit, the ANOVA tables summarizes the test for no differences in trends
among the EcoDomains in @tbl-em-test-eco-slopes.

```{r}
#| echo: false
#| message: false
#| warning: false
#| tbl-cap: "ANOVA table for testing for differences in trends among EcoDomains"
#| label: tbl-em-test-eco-slopes

#temp <-anova(count.fit, ddf="Kenward-Roger")
temp <-anova(count.fit, ddf="Satterthwaite")
#temp

count.fit.pvalue.parallel <- temp[3,"Pr(>F)"]
count.fit.slope  <- fixef(count.fit)[2]
count.fit.slope.se <- sqrt(diag(vcov(count.fit)))[2]

count.fit.slope.anti <- exp(count.fit.slope)

temp<- tidy(temp)
temp$p.value <- insight::format_p(temp$p.value)
temp$sumsq <-NULL
temp$meansq <- NULL
temp$statistic <- NULL
temp$term <- gsub("F$","", temp$term)

ft <- flextable(temp)
ft <- set_header_labels(ft, term="Source" )
ft <- width(ft, j="p.value", width=2, unit="in")
ft <- colformat_double(ft, j="DenDF", digits=1)
ft


```

The *Year:ECODOMAIN* term tests the hypothesis that the slopes in all of the EcoDomains are equal. If the p-value is large,
then there is no evidence that the slopes among the EcoDomains are different.

### Estimated slopes

The estimated coefficients from *R* output above do not have a direct interpretation because of the way that *R* codes the
design matrix for discrete variables such as the EcoDomain.These coefficients associated with each EcoDomain
are the difference in the slopes between the slope for that particular EcoDomain and the reference EcoDomain (typically
the EcoDomain that is "first" alphabetically).

The estimated slope for each EcoDomain are estimated using the *emmeans* package (Lenth, 2023) presented in @tbl-em-slope-ecodomains.

```{r}
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Estimated slope in each EcoDomain"
#| label: tbl-em-slope-ecodomains

# get the individaul slopes for each ecomean
eco.slopes.emmo <- emmeans::emtrends(count.fit, "ECODOMAINF", var="Year", mode="satterthwaite")
temp <- multcomp::cld(eco.slopes.emmo)

eco.slopes.df <- as.data.frame(summary(eco.slopes.emmo, infer=TRUE))
eco.slopes.df$ECODOMAIN <- as.character(eco.slopes.df$ECODOMAINF)

eco.slopes.d1        <- as.character(eco.slopes.df[1,"ECODOMAINF"])
eco.slopes.d1.slope  <- eco.slopes.df[1,"Year.trend"]

ft <- flextable(as.data.frame(temp))
ft <- width(ft, j=1, width=1, unit="in")
ft <- set_header_labels(ft, ECODOMAINF="Eco Domain", Year.trend="Slope", SE='SE', df='df', lower.CL='95% LCL', upper.CL='95% UCL', .group='Grouping')
ft <- colformat_double(ft, j=c(2,3,5,6), digits=4)
ft <- colformat_double(ft, j="df", digits=1)
ft <- add_footer_lines(ft, top = TRUE, values = attr(temp,"mesg"))
ft
```

The estimated trends (on the logarithmic scale) can be interpretted as the proportional change per year.
For example, the slope of `r round(eco.slopes.d1.slope,3)` in the `r eco.slopes.d1` EcoDomain can be interpretted
as an approximate `r round(eco.slopes.d1.slope*100,1)`% change in the mean call rate per year.

The *Grouping* column indicates if there is evidence of a difference among the slopes across EcoDomains.
EcoDomains that contain the same "digit" would indicate no evidence of a difference in the mean slopes
among the EcoDomains. This is a summary of the overall p-value for parallelism found in the ANOVA table of
`r insight::format_p(count.fit.pvalue.parallel)`. For more information on interpretting the *.group* variable,
refer to https://schmidtpaul.github.io/DSFAIR/compactletterdisplay.html.

### Mean slope over all EcoDomains

The average slope over all EcoDomains (giving each EcoDomain equal weight regardless of the number of study areas 
in the EcoDomain) shown in @tbl-em-slope-mean.

```{r}
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Estimated mean slope over all EcoDomains"
#| label: tbl-em-slope-mean

# get the mean slopes over all EcoDomains
eco.slopes.mean <- emmeans::emtrends(count.fit, ~1, var="Year", mode="satterthwaite")
temp <- summary(eco.slopes.mean, infer=TRUE)

eco.slopes.mean.df        <- as.data.frame(summary(eco.slopes.mean, infer=TRUE))
eco.slopes.mean.slope     <- eco.slopes.mean.df[1,"Year.trend"]
eco.slopes.mean.slope.se  <- eco.slopes.mean.df[1,"SE"]
eco.slopes.mean.slope.p   <- eco.slopes.mean.df[1,"p.value"]


temp$t.ratio <- NULL
temp$p.value <- insight::format_p(temp$p.value)

ft <- flextable(as.data.frame(temp))
ft <- width(ft, j=1, width=1, unit="in")
ft <- width(ft, j="p.value", width=1, unit="in")
ft <- set_header_labels(ft, '1'="Mean slope", Year.trend="Slope", SE='SE', df='df', lower.CL='95% LCL', upper.CL='95% UCL', .group='Grouping')
ft <- colformat_double(ft, j=c(2,3,5,6), digits=4)
ft <- colformat_double(ft, j="df", digits=1)
ft <- add_footer_lines(ft, top = TRUE, values = attr(temp,"mesg"))
ft
```

The overall average slope over all EcoDomain is 
`r round(eco.slopes.mean.slope,3)` (SE `r round(eco.slopes.mean.slope.se,3)` with a p-value of
`r insight::format_p(eco.slopes.mean.slope.p)`. This is the same p-value from the ANOVA table
for the *Year* term.

The estimated mean slope is interpreted in the same way as the slopes for each EcoDomain.

### Summary plot

@fig-em-trend shows a summary plot, along with estimates of the slope, its standard error,
and the p-value of the hypothesis of no trend in each EcoDomain.

```{r}
#| echo: false
#| fig-cap: "Summary plot of the trend in mean squirrel counts."
#| label: fig-em-trend
#| warning: false
#| message: false


# compute the fitted values from the model
# The model was run on the log(average count+.5), so we need to back transform
count.fitted <- unique( eggmass.count.all[,c("ECODOMAIN","ECODOMAINF","STUDY_AREA_NAME","STUDY_AREA_NAMEF","STUDY_AREA_NAME_shrt")])
count.fitted <- plyr::adply(count.fitted,1,function(x,min.year,max.year){
    Year <- seq(min.year, max.year, .1)
    x <- x[rep(1, length(Year)),]
    x$Year <- Year
    x
}, min.year=min(eggmass.count.all$Year, na.rm=TRUE), max.year=max(eggmass.count.all$Year, na.rm=TRUE))

# get the EcoDomain predictions
count.fitted$pred.ecodomain.mean.log <- predict(count.fit, newdata=count.fitted,type="response", re.form=~0) 
count.fitted$pred.ecodomain.mean <- exp(count.fitted$pred.ecodomain.mean.log) - .5
#head(count.fitted)

fitted.em.plot <- ggplot(data=eggmass.count.all, aes(x=Year, y=log(EggMasses+.5)))+
   ggtitle("EggMass count (all species) data")+
   ylab("log(EggMass Count + .5)")+
   geom_point(position=position_dodge(width=.1))+
   geom_line( aes(group=SA.TRANSECT, color=STUDY_AREA_NAME_shrt), position=position_dodge(width=.1))+
   facet_wrap(~ECODOMAIN, ncol=2)+
   scale_x_continuous(breaks=integer_breaks())+
   geom_line(data=count.fitted, aes(y=pred.ecodomain.mean.log), color="red")+
   geom_text(data=eco.slopes.df, aes(label=paste0("Slope :", round(Year.trend,3),
                                                  " (SE ",round(SE,3),") ",
                                                  insight::format_p(p.value)
                                                  ), x=-Inf, y=Inf), vjust=1.5, hjust=-0.1)+
   xlab("Year\nRed line is fitted line for the EcoDomain")
fitted.em.plot 
ggsave(plot=fitted.em.plot, 
       file=file.path(file.prefix,'Plot-em-Fitted-trend.png'),
       h=4, w=6, units="in",dpi=300)


```

### Estimated variance component

The estimated variance components are shown in @tbl-em-var-comp.

```{r}
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Estimated variance components"
#| label: tbl-em-var-comp


temp <- as.data.frame(VarCorr(count.fit))
temp$vcov <- NULL
temp$grp <- gsub("F$","", temp$grp)
#temp$var1 <- NULL
temp$var1 <- gsub("(Intercept)","", temp$var1, fixed=TRUE)
temp$var2 <- NULL

ft <- flextable(temp)
ft <- set_header_labels(ft, grp="Component", var1="Interaction",sdcor="SD")
ft <- width(ft, j=1, width=2, unit="in")
ft <- width(ft, j=2, width=1, unit="in")
ft <- colformat_double(ft, j="sdcor", digits=3)
ft

```

The *STUDY_AREA_NAME* and *STUDY_AREA_NAME:Year* represent the variation in the intercepts and slopes among study areas within
an EcoDomain. The *TRANSECT* component represents the variation in intercepts among multiple transects within the same STUDY_AREA.
The *YearF:ECODOMAIN* components represents the variation in the year specific factors (process error) within the EcoDomains.
Finally the *Residual* component represents the left-over, unexplained variation in the data.

Notice in this case, that the variation in the slopes for each STUDY_AREA within the EcoDomains is very close to 0, i.e., the
different study areas could all have similar slopes within the EcoDomain. If you examine the individual slopes in each study area
(see the individual study area reports), the estimated standard error is quite large indicating the the slopes could be roughly
the same across study areas (see @fig-em-indiv-slopes).


```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Comparing the individual slopes within each EcoRegion"
#| label: fig-em-indiv-slopes

# estimate the slopes for each study area individually
indiv.slopes <- plyr::ddply(eggmass.count, c("STUDY_AREA_NAME","STUDY_AREA_NAME_shrt","ECODOMAIN"), function (x){
    #browser()
    slope <- tryCatch({
        count.fit <- lmerTest::lmer(log(EggMasses+.5) ~ Year + (1|TRANSECTF) + (1|YearF), data=x)#, lmerControl(optimizer="bobyqa"))
        slope           = fixef(count.fit)["Year"]
        slope.se        = summary(count.fit)$coefficients["Year","Pr(>|t|)"]
        p.value         = summary(count.fit)$coefficients[row.names(summary(count.fit)$coefficients)=="Year"  ,"Pr(>|t|)"] 
        data.frame(slope=slope, slope.se=slope.se, p.value=p.value)
        },
        error=function(cond) {
            return(data.frame(slope=NA, slope.se=NA, p.value=NA))
        }
        )
})

ggplot(data=indiv.slopes, aes(x=slope, y=STUDY_AREA_NAME_shrt))+
   geom_point()+
   geom_errorbarh(aes(xmin=slope-1.96*slope.se, xmax=slope+1.96*slope.se), height=.1)+
   facet_wrap(~ECODOMAIN, ncol=1, scales="free_y")+
   geom_vline(data=eco.slopes.df, aes(xintercept=Year.trend, y=NULL), color="red")+
   coord_cartesian(xlim=c(-1,1))

```




The year specific effects vary slightly among the EcoDomains as shown in @fig-em-year-effects.

```{r}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: "Plot of year specific effects"
#| label: fig-em-year-effects

year.eff <- ranef(count.fit)$`YearF:ECODOMAINF`
names(year.eff)[1] <- "year.effect"
year.eff$Year <- as.numeric(substr(row.names(year.eff),1,4))
year.eff$ecodomain <- substring(row.names(year.eff),6)


ggplot(data=year.eff, aes(x=Year, y=year.effect, color=ecodomain))+
  ggtitle("Estimated year-specific effects")+
  geom_point()+
  geom_line()+
  geom_hline(yintercept=0)+
  scale_x_continuous(breaks=2000:3000)+
  ylab("Year specific effects")
```

We see that the year-specific effects can vary across EcoDomains, e.g., 
the year-specific impact of weather can be different in the different EcoDomains.
This is not surprising because B.C. is a large Province!



### Residual plots

Residual plots are presented in @fig-em-count-resid.

```{r}
#| echo: false
#| fig-cap: "Model fit diagnostic plots from trend in mean transect counts"
#| label: fig-em-count-resid
#| warning: false
#| message: false

# Look at the residual plots and save them to the directory
diag.plot <- sf.autoplot.lmer(count.fit)  # residual and other diagnostic plots
plot(diag.plot)
ggsave(plot=diag.plot, 
       file=file.path(file.prefix,"Plot-Residual.png"),
       h=6, w=6, units="in", dpi=300)

```

In the upper left corner is a plot of residuals vs. 
the fitted values. A good plot will show a random scatter around 0. 
Any large deviations from 0 should be investigated as potential outliers. 
In the upper right is a normal probability plot. Points should be close to the dashed reference line. 
Fortunately, the analysis is fairly robust against non-normality so only extreme departures are worrisome. 
Caterpiller plots attempt to show the distribution of the random effects. 
The bottom left plot shows the distribution of the transect effects. 
The bottom right plot shows the distribution of the year-specific effects (process variation). 
In this case, the estimated process variation is very small with most of points very close to 0.


## Adult counts

**A similar analysis can be done, but pending revisions to the database, this is not done here **

# Summary

This analysis examines trends across EcoDomains. The model has an overall average trend, a EcoDomain specific trend,
and random trends for each Study Area among the EcoDomain trends. With many study areas and many years of data collected
in each study area, the design has a high power to detect even a moderate trend over time.

This model used the approximate analysis on the logarithm of the average counts per transect. 
It is possible to analyze the actual raw counts using a generalized linear mixed model – 
this was not done in this example because of the extreme smallness of the dataset. 
Once many more years are collected, this may be an alternative analysis 
that will more naturally deal with 0 counts without having to add a small constant.

# References

Kuznetsova A, Brockhoff PB, Christensen RHB (2017).
“lmerTest Package: Tests in Linear Mixed Effects Models.” 
Journal of Statistical Software, 82, 1-26. 
doi:10.18637/jss.v082.i13 <https://doi.org/10.18637/jss.v082.i13>.

Lenth R (2023). emmeans: Estimated Marginal Means, aka Least-Squares Means.
R package version 1.8.4-1,
  <https://CRAN.R-project.org/package=emmeans>.

R Core Team (2032). R: A language and environment for statistical computing. 
R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

